# Feature selection stages - Parallelized to use multi-core CPUs using the multiprocessing python package

## Description
* Forward feature selection (custom implementation) code is provided, which can be adapted to multiple machine learning models
* The first four sample commands must be iteratively run for performing successive feature combinations (preferably using a shell script) till the desired accuracy is reached (in forward feature selection)
* Stratified 10-fold cross validation and jack-knife tests are performed only on the best models from each iteration to save time taken to evaluate feature combinations

## Prerequisites
* Anaconda or Miniconda with Python 3.8.
* A conda environment with the following libraries:
	* Python (>v3.8)
	* pandas
	* numpy
	* scipy
	* scikit-learn
	* pickle
	* matplotlib
	* seaborn
	* multiprocessing
	* tqdm
	* Generic libraries: sys, re, csv, os, collections...

## Sample commands (Follow the same order to reproduce the files provided in sample_output folder)
```
* python -u ffs_final.py "./data/Pocket_dataset_final.csv" "./data/Pocket_features_pairwise_corrdict_v1.pkl" 1 <nfeat> "all" <output path>
* python -u process_regression_output_v1.py <output from previous program> "pass_models.log" "best_models.log"
* python -u get_desc_stats_v1.py "best_models.log" <nfeat> "feat_stats.out" "feat_pass.out"
* python -u process_regression_output_v2.py "best_prev_models.log" "best_current_models.log" <prev_nfeat> "prev_vs_current_best_models.log"
* python -u perform_LOO_CV.py "./data/Pocket_dataset_final.csv" "best_models.log" <nfeat> 3 <output path>
```

## Miscellaneous
* In `process_regression_output_v1.py`, the user should modify the correlation cut-off for filtering the best models from the ones generated by the feature combination code. Using the default cut-off value can lead to zero results and subsequent errors in processing.
* In `ffs_final.py`, the keyword "all" needs to be replaced with the output file (feat_pass.out) from `get_desc_stats_v1.py` for using the features with best performance from the previous feature combination iteration.
* All programs take inputs as command-line arguments only
* The same pipeline is followed to prepare all custom test datasets used in the study, in the format necessary for model evaluation
* The header fields or columns provided in the sample dataset must be present (column order can be random) in your custom dataset file for the programs to work in the intended fashion
